

## **Week 9 â€“ Day 3 (20 Jan) â†’ Feature Engineering (Deep + Practical)**

**Goal:**
Raw data âžœ clean âžœ numerical âžœ scaled âžœ ML-ready

> Model se pehle **features powerful honi chahiye**.

---

## â±ï¸ **Time Plan (2â€“3 hours)**

---

## **Hour 1: Categorical â†’ Numerical (Encoding)**

ML models **strings nahi samajhte**, sirf numbers.

### 1ï¸âƒ£ Identify categorical columns

```python
df.select_dtypes(include="object").columns
```

Titanic mein usually:

* Sex
* Embarked

---

### 2ï¸âƒ£ Label Encoding (Binary case)

```python
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
df["Sex"] = le.fit_transform(df["Sex"])
```

ðŸ§  Result:

* male â†’ 1
* female â†’ 0

**Use when:** sirf 2 categories ho.

---

### 3ï¸âƒ£ One-Hot Encoding (Best Practice)

```python
df = pd.get_dummies(df, columns=["Embarked"], drop_first=True)
```

ðŸ§  **Why drop_first?**
Multicollinearity avoid hoti hai.

âœ… **Best Practice:**

* Binary â†’ LabelEncoder
* Multiple categories â†’ One-Hot Encoding

---

## **Hour 2: Feature Selection + Scaling**

### 4ï¸âƒ£ Select Features & Target

```python
X = df[["Age", "Fare", "Sex", "Pclass"]]
y = df["Survived"]
```

âŒ **Avoid:**

* PassengerId
* Name
* Ticket

(Ye ML ko confuse karte hain)

---

### 5ï¸âƒ£ Feature Scaling (VERY IMPORTANT)

Especially for **Logistic Regression & KNN**

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

ðŸ§  **What scaling does?**

* Mean = 0
* Std = 1
* Large values dominance khatam

---

### 6ï¸âƒ£ Train-Test Split

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)
```

ðŸ§  **Rule:**
Never train & test on same data âŒ

---

## **Hour 3: Feature Insight + Practice**

### 7ï¸âƒ£ Feature Importance (Manual Thinking)

Ask yourself:

* Age survival ko affect karta?
* Fare rich vs poor?
* Gender impact?

ML engineer **logic bhi lagata hai**, sirf code nahi.

---

### ðŸ§ª **Mini Practice (Must Do)**

```python
print("Train shape:", X_train.shape)
print("Test shape:", X_test.shape)
print("Target distribution:\n", y.value_counts(normalize=True))
```

---

## âŒ **Common Mistakes**

* Scaling ke baad `y` ko scale karna âŒ
* Train-test split se pehle scaling âŒ
* Random columns add kar dena âŒ

---

## âœ… **Day 3 Takeaways**

* Feature engineering > model choice
* Encoding converts language â†’ numbers
* Scaling is compulsory for distance-based models
* Clean features = stable ML pipeline

---
