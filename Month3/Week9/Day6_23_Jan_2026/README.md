## **Week 9 ‚Äì Day 6 (23 Jan) ‚Üí KNN (Deep + Practical)**

**Goal:**

* Distance-based classification samajhna
* Train & test KNN model
* Feature scaling ka importance practice karna

---

## ‚è±Ô∏è **Time Plan (2‚Äì3 hours)**

---

### **Hour 1: Conceptual Understanding**

1Ô∏è‚É£ **KNN Kya Hai?**

* Predict **class of a point** based on **closest neighbors**
* ‚ÄúNearby passengers ka survival kaisa tha?‚Äù ‚Üí Decide new passenger survival
* Non-parametric model ‚Üí no explicit training, **just store training data**

2Ô∏è‚É£ **Hyperparameters**

* `n_neighbors` ‚Üí kitne neighbors check karein
* `weights` ‚Üí uniform or distance
* **Distance metric:** Euclidean (default)

üí° **Tip:** Scaling **must** hai kyunki distance sensitive hai

---

### **Hour 2: Train KNN Model**

Assume **Day 3 features ready** (`X_train, X_test, y_train, y_test`)

```python
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix

knn = KNeighborsClassifier(n_neighbors=3)  # 3 nearest neighbors
knn.fit(X_train, y_train)

y_pred_knn = knn.predict(X_test)
```

---

### **Hour 3: Evaluate + Experiment**

1Ô∏è‚É£ **Accuracy + Confusion Matrix**

```python
print("Accuracy:", accuracy_score(y_test, y_pred_knn))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_knn))
```

2Ô∏è‚É£ **Experiment with neighbors**

```python
for k in [1,3,5,7]:
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)
    y_pred = knn.predict(X_test)
    print(f"K={k}, Accuracy={accuracy_score(y_test,y_pred)}")
```

3Ô∏è‚É£ **Optional: Weighted KNN**

```python
knn = KNeighborsClassifier(n_neighbors=5, weights='distance')
knn.fit(X_train, y_train)
print("Weighted KNN Accuracy:", accuracy_score(y_test, knn.predict(X_test)))
```

---

### **Mini Practice (Must Do)**

* Try changing `n_neighbors` ‚Üí observe accuracy
* Remove scaling ‚Üí observe big drop in accuracy
* Predict **single passenger** survival

```python
sample = X_test[0].reshape(1,-1)
print(knn.predict(sample))
```

---

### ‚ùå **Common Mistakes**

* Skip scaling ‚Üí distance wrong ‚ùå
* Too large/small `k` ‚Üí under/overfitting ‚ùå
* Use categorical features without encoding ‚ùå

---

### ‚úÖ **Day 6 Takeaways**

1. KNN = distance-based, simple, intuitive
2. Feature scaling **must** for distance models
3. n_neighbors tuning ‚Üí model performance
4. Weighted KNN ‚Üí better predictions in imbalanced data

---