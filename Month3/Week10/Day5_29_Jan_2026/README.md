# Day 5 â€“ Test Iris ML API with Redis

**Objective:**  
Test the Iris ML API built with **FastAPI** and **Redis caching**, ensuring correct predictions and cache functionality.

---

## ğŸ§© Project Overview

- ML Model: **RandomForestClassifier** trained on Iris dataset
- API Framework: **FastAPI**
- Caching: **Redis** for repeated predictions
- Features:
  - `/predict` endpoint
  - Input validation via **Pydantic**
  - Cache check â†’ Redis â†’ ML model

---

## ğŸ— Project Structure

```

iris_api/
â”‚
â”œâ”€â”€ app/
|   â”œâ”€â”€Test
|   |  â””â”€â”€ main.py
â”‚   â”œâ”€â”€ main.py        # FastAPI app
â”‚   â”œâ”€â”€ model.py       # Load & predict ML model
â”‚   â”œâ”€â”€ schema.py      # Request/Response validation
â”‚   â””â”€â”€ redis_cache.py # Redis client
â”‚
â”œâ”€â”€ train.py           # Train and save model
â”œâ”€â”€ model.pkl          # Saved ML model
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

````

---

## âš¡ Installation Steps

1. Clone repository:
```bash
git clone <repo_url>
cd iris_api
````

2. Install dependencies:

```bash
pip install -r requirements.txt
```

3. Start Redis server (ensure it is running):

```bash
redis-server
```

4. Train ML model (first time only):

```bash
python train.py
```

5. Start FastAPI server:

```bash
uvicorn app.main:app --reload
```

---

## ğŸ§ª Testing the API

### 1ï¸âƒ£ Swagger UI (Recommended)

* Open: `http://127.0.0.1:8000/docs`
* Go to `POST /predict`
* Click **Try it out**
* Example input:

```json
{
  "sepal_length": 5.1,
  "sepal_width": 3.5,
  "petal_length": 1.4,
  "petal_width": 0.2
}
```

* Click **Execute**
* Response:

```json
{
  "source": "ml_model",
  "prediction": 0
}
```

* Repeat same input â†’ `"source": "redis_cache"` confirms caching works

---

### 2ï¸âƒ£ Python Script

```python
import requests

url = "http://127.0.0.1:8000/predict"

data = {
    "sepal_length": 6.0,
    "sepal_width": 3.0,
    "petal_length": 4.8,
    "petal_width": 1.8
}

response = requests.post(url, json=data)
print(response.json())
```

* Expected Output:

```json
{"source": "ml_model", "prediction": 2}
```

* Repeat same input â†’ `"source": "redis_cache"`

---

### 3ï¸âƒ£ cURL (Terminal)

```bash
curl -X POST "http://127.0.0.1:8000/predict" \
-H "Content-Type: application/json" \
-d '{"sepal_length":5.1,"sepal_width":3.5,"petal_length":1.4,"petal_width":0.2}'
```

---

## ğŸ” Notes & Best Practices

* Ensure **Redis server** is running before testing
* Test **Swagger UI first**, then scripts for automation
* Redis caching improves repeated prediction performance
* For production:

  * Map prediction index â†’ Iris species names
  * Use Redis expiry (`setex`) to manage cache memory
  * Dockerize the project for deployment

---